{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":false},"outputs":[],"source":"# coding = utf-8\nimport mxnet as mx\nfrom mxnet.gluon import data, HybridBlock, nn\nimport pandas as pd\nimport cv2\nimport os\nimport numpy as np\nfrom mxnet.gluon.data.vision import transforms\nfrom mxnet.gluon.model_zoo import vision\nimport glob\nfrom mxnet import nd as F, gluon\nfrom gluoncv import model_zoo as gm"},{"cell_type":"code","execution_count":0,"metadata":{"_cell_guid":"62d10afb-5db7-4a04-a39e-cb52c11f0066","_uuid":"dfb28b7c-88eb-4f75-87cb-f376563418c3","trusted":false},"outputs":[],"source":"%pylab inline"},{"cell_type":"code","execution_count":0,"metadata":{"_cell_guid":"5c428301-716f-4145-85ab-039aa0f201d0","_uuid":"f1760ed3-3fe8-4262-a9cd-fbbf4e0c26b3","trusted":false},"outputs":[],"source":"ls ../input/mxnet-gluon-baseline/model/"},{"cell_type":"code","execution_count":0,"metadata":{"_cell_guid":"b604b7d4-8f98-4892-9f4e-b6f2655fffbe","_uuid":"affe1664-33ee-442d-b8b5-3ef17bd18a1b","trusted":false},"outputs":[],"source":"from gluoncv.model_zoo.resnetv1b import resnet50_v1s, resnet101_v1s, resnet152_v1s\nimport mxnet as mx\nfrom mxnet.gluon import nn\nfrom mxnet.gluon.nn import HybridBlock\n\nclass ResNetBackbone(mx.gluon.HybridBlock):\n    def __init__(self, backbone='resnet50', pretrained_base=True,dilated=True, **kwargs):\n        super(ResNetBackbone, self).__init__()\n\n        with self.name_scope():\n            if backbone == 'resnet50':\n                pretrained = resnet50_v1s(pretrained=pretrained_base, dilated=dilated, **kwargs)\n            elif backbone == 'resnet101':\n                pretrained = resnet101_v1s(pretrained=pretrained_base, dilated=dilated, **kwargs)\n            elif backbone == 'resnet152':\n                pretrained = resnet152_v1s(pretrained=pretrained_base, dilated=dilated, **kwargs)\n            else:\n                raise RuntimeError(f'unknown backbone: {backbone}')\n\n            self.conv1 = pretrained.conv1\n            self.bn1 = pretrained.bn1\n            self.relu = pretrained.relu\n            self.maxpool = pretrained.maxpool\n            self.layer1 = pretrained.layer1\n            self.layer2 = pretrained.layer2\n            self.layer3 = pretrained.layer3\n            self.layer4 = pretrained.layer4\n\n    def hybrid_forward(self, F, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        c1 = self.layer1(x)\n        c2 = self.layer2(c1)\n        c3 = self.layer3(c2)\n        c4 = self.layer4(c3)\n\n        return c1, c2, c3, c4"},{"cell_type":"code","execution_count":0,"metadata":{"_cell_guid":"eef18cff-f88b-4ad0-9a54-f341d5139088","_uuid":"90cf8da7-3758-40d5-b813-5a3230036de4","trusted":false},"outputs":[],"source":"import mxnet as mx\nfrom mxnet.gluon import nn\nfrom mxnet.gluon.nn import HybridBlock\n\nclass ResNetFPN(mx.gluon.HybridBlock):\n    def __init__(self, backbone= 'resnet50', backbone_lr_mult=0.1, **kwargs):\n        super(ResNetFPN, self).__init__()\n\n        self.backbone_name = backbone\n        self.backbone_lr_mult = backbone_lr_mult\n        self._kwargs = kwargs\n\n        with self.name_scope():\n            self.backbone = ResNetBackbone(backbone=self.backbone_name, pretrained_base=False, dilated=False, **kwargs)\n\n            self.head = _FPNHead(output_channels=256, **kwargs)\n\n    def load_pretrained_weights(self):\n        pretrained = ResNetBackbone(backbone=self.backbone_name, pretrained_base=True, dilated=False, **self._kwargs)\n        backbone_params = self.backbone.collect_params()\n        pretrained_weights = pretrained.collect_params()\n        for k, v in pretrained_weights.items():\n            param_name = backbone_params.prefix + k[len(pretrained_weights.prefix):]\n            backbone_params[param_name].set_data(v.data())\n\n        self.backbone.collect_params().setattr('lr_mult', self.backbone_lr_mult)\n\n    def hybrid_forward(self,F, x):\n        c1, c2, c3, c4 = self.backbone(x)\n        p1, p2, p3, p4 = self.head(c1, c2, c3, c4)\n\n        return p1, p2, p3, p4\n\nclass ResNetUnet(mx.gluon.HybridBlock):\n    def __init__(self, backbone= 'resnet50', backbone_lr_mult=0.1, cls_branch=False, **kwargs):\n        super(ResNetUnet, self).__init__()\n\n        self.backbone_name = backbone\n        self.backbone_lr_mult = backbone_lr_mult\n        self.cls_branch = cls_branch\n        self._kwargs = kwargs\n        \n        with self.name_scope():\n            self.backbone = ResNetBackbone(backbone=self.backbone_name, pretrained_base=False, dilated=False, **kwargs)\n\n            self.head = _UnetHead(**kwargs)\n\n    def load_pretrained_weights(self):\n        pretrained = ResNetBackbone(backbone=self.backbone_name, pretrained_base=True, dilated=False, **self._kwargs)\n        backbone_params = self.backbone.collect_params()\n        pretrained_weights = pretrained.collect_params()\n        for k, v in pretrained_weights.items():\n            param_name = backbone_params.prefix + k[len(pretrained_weights.prefix):]\n            backbone_params[param_name].set_data(v.data())\n\n        self.backbone.collect_params().setattr('lr_mult', self.backbone_lr_mult)\n\n    def hybrid_forward(self,F, x):\n        c1, c2, c3, c4 = self.backbone(x)\n        out = self.head(c1, c2, c3, c4)\n        if self.cls_branch:\n            logits = F.max(F.mean(out, axis=1), axis=(1, 2))\n            return out, logits\n        return out\n\nclass _DecoderBlock(HybridBlock):\n    def __init__(self, output_channels, norm_layer=nn.BatchNorm):\n        super(_DecoderBlock, self).__init__()\n\n        with self.name_scope():\n            self.block = nn.HybridSequential()\n            self.block.add(ConvBlock(output_channels, kernel_size=3, padding=1, norm_layer=norm_layer))\n            self.block.add(ConvBlock(output_channels, kernel_size=3, padding=1, norm_layer=norm_layer))\n\n    def hybrid_forward(self, F, x, y=None):\n\n        if y is not None:\n            x = F.contrib.BilinearResize2D(x, scale_height=2, scale_width=2)\n            x = F.concat(x, y, dim=1)\n        out = self.block(x)\n\n        return out\n\n\nclass _UnetHead(HybridBlock):\n    def __init__(self, num_classes, output_channels=[256, 128, 64, 32], scale=4, norm_layer=nn.BatchNorm):\n        super(_UnetHead, self).__init__()\n        \n        self.scale = scale\n        with self.name_scope():\n            self.block4 = _DecoderBlock(output_channels[0], norm_layer=norm_layer)\n            self.block3 = _DecoderBlock(output_channels[1], norm_layer=norm_layer)\n            self.block2 = _DecoderBlock(output_channels[2], norm_layer=norm_layer)\n            self.block1 = _DecoderBlock(output_channels[3], norm_layer=norm_layer)\n            self.postprocess_block = nn.Conv2D(num_classes, kernel_size=1)\n\n    def hybrid_forward(self, F, c1, c2, c3, c4):\n\n        p4 = self.block4(c4)\n        p3 = self.block3(p4, c3)\n        p2 = self.block2(p3, c2)\n        p1 = self.block1(p2, c1)\n        if self.scale > 1:\n            p1 = F.contrib.BilinearResize2D(p1, scale_height=self.scale, scale_width=self.scale)\n        out = self.postprocess_block(p1)\n\n        return out\n\n\nclass _FPNHead(HybridBlock):\n    def __init__(self, output_channels=256, norm_layer=nn.BatchNorm):\n        super(_FPNHead, self).__init__()\n        self._hdsize = {}\n\n        with self.name_scope():\n            self.block4 = ConvBlock(output_channels, kernel_size=1, norm_layer=norm_layer)\n            self.block3 = ConvBlock(output_channels, kernel_size=1, norm_layer=norm_layer)\n            self.block2 = ConvBlock(output_channels, kernel_size=1, norm_layer=norm_layer)\n            self.block1 = ConvBlock(output_channels, kernel_size=1, norm_layer=norm_layer)\n\n    def hybrid_forward(self, F, c1, c2, c3, c4):\n        p4 = self.block4(c4)\n        p3 = self._resize_as(F, 'id_1', p4, c3) + self.block3(c3)\n        p2 = self._resize_as(F, 'id_2', p3, c2) + self.block2(c2)\n        p1 = self._resize_as(F, 'id_3', p2, c1) + self.block1(c1)\n\n        return p1, p2, p3, p4\n\n    def _resize_as(self, F, name, x, y):\n        h_key = name + '_h'\n        w_key = name + '_w'\n\n        if hasattr(y, 'shape'):\n            _, _, h, w = y.shape\n            _, _, h2, w2 = x.shape\n\n            if h == h2 and w == w2:\n                h = 0\n                w = 0\n\n            self._hdsize[h_key] = h\n            self._hdsize[w_key] = w\n        else:\n            h, w = self._hdsize[h_key], self._hdsize[w_key]\n\n        if h == 0 and w == 0:\n            return x\n        else:\n            return F.contrib.BilinearResize2D(x, height=h, width=w)\n\n\nclass SemanticFPNHead(HybridBlock):\n    def __init__(self, num_classes, output_channels=128, norm_layer=nn.BatchNorm):\n        super(SemanticFPNHead, self).__init__()\n        self._hdsize = {}\n\n        with self.name_scope():\n            self.block4_1 = ConvBlock(output_channels, kernel_size=3, padding=1, norm_layer=norm_layer)\n            self.block4_2 = ConvBlock(output_channels, kernel_size=3, padding=1, norm_layer=norm_layer)\n            self.block4_3 = ConvBlock(output_channels, kernel_size=3, padding=1, norm_layer=norm_layer)\n\n            self.block3_1 = ConvBlock(output_channels, kernel_size=3, padding=1, norm_layer=norm_layer)\n            self.block3_2 = ConvBlock(output_channels, kernel_size=3, padding=1, norm_layer=norm_layer)\n\n            self.block2 = ConvBlock(output_channels, kernel_size=3, padding=1, norm_layer=norm_layer)\n            self.block1 = ConvBlock(output_channels, kernel_size=1, norm_layer=norm_layer)\n\n            self.postprocess_block = nn.Conv2D(num_classes, kernel_size=1)\n\n    def hybrid_forward(self, F, c1, c2, c3, c4):\n        out4 = self._resize_as(F, 'id_1', self.block4_1(c4), c3)\n        out4 = self._resize_as(F, 'id_2', self.block4_2(out4), c2)\n        out4 = self._resize_as(F, 'id_3', self.block4_3(out4), c1)\n\n        out3 = self._resize_as(F, 'id_4', self.block3_1(c3), c2)\n        out3 = self._resize_as(F, 'id_5', self.block3_2(out3), c1)\n\n        out2 = self._resize_as(F, 'id_6', self.block2(c2), c1)\n\n        out1 = self.block1(c1)\n\n        out = out1 + out2 + out3 + out4\n\n        out = self.postprocess_block(out)\n        out = F.contrib.BilinearResize2D(out,scale_height=4,scale_width=4)\n        return out\n\n    def _resize_as(self, F,name, x, y):\n        h_key = name + '_h'\n        w_key = name + '_w'\n\n        if hasattr(y, 'shape'):\n            _, _, h, w = y.shape\n            _, _, h2, w2 = x.shape\n\n            if h == h2 and w == w2:\n                h = 0\n                w = 0\n\n            self._hdsize[h_key]=h\n            self._hdsize[w_key]=w\n        else:\n            h, w = self._hdsize[h_key], self._hdsize[w_key]\n\n        if h == 0 and w == 0:\n            return x\n        else:\n            return F.contrib.BilinearResize2D(x,height=h,width=w)\n\n\nclass ConvBlock(HybridBlock):\n    def __init__(self, output_channels, kernel_size, padding=0, activation='relu', norm_layer=nn.BatchNorm):\n        super().__init__()\n        self.body = nn.HybridSequential()\n        self.body.add(\n            nn.Conv2D(output_channels, kernel_size=kernel_size, padding=padding, activation=activation),\n            norm_layer(in_channels=output_channels)\n        )\n\n    def hybrid_forward(self, F, x):\n        return self.body(x)\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"\nclass ResNetSteel(mx.gluon.HybridBlock):\n    def __init__(self, backbone= 'resnet50', num_classes=4, backbone_lr_mult=0.1, **kwargs):\n        super(ResNetSteel, self).__init__()\n\n        self.backbone_name = backbone\n        self.backbone_lr_mult = backbone_lr_mult\n        self._kwargs = kwargs\n\n        with self.name_scope():\n            self.backbone = ResNetBackbone(backbone=self.backbone_name, pretrained_base=False, dilated=False, **kwargs)\n\n            self.head = Classification_head(output_channels=256, num_classes=num_classes)\n\n    def load_pretrained_weights(self):\n        pretrained = ResNetBackbone(backbone=self.backbone_name, pretrained_base=True, dilated=False, **self._kwargs)\n        backbone_params = self.backbone.collect_params()\n        pretrained_weights = pretrained.collect_params()\n        for k, v in pretrained_weights.items():\n            param_name = backbone_params.prefix + k[len(pretrained_weights.prefix):]\n            backbone_params[param_name].set_data(v.data())\n\n        self.backbone.collect_params().setattr('lr_mult', self.backbone_lr_mult)\n\n    def hybrid_forward(self,F, x):\n        c1, c2, c3, c4 = self.backbone(x)\n        logits = self.head(c4)\n\n        return logits\n\nclass Classification_head(HybridBlock):\n    def __init__(self, output_channels=256, num_classes=4):\n        super(Classification_head, self).__init__()\n\n        with self.name_scope():\n            self.cls_head = nn.HybridSequential()\n            self.cls_head.add(ConvBlock(output_channels, kernel_size=1))\n            self.cls_head.add(nn.GlobalAvgPool2D())\n            self.cls_head.add(nn.Conv2D(num_classes, kernel_size=1))\n\n    def hybrid_forward(self, F, x):\n        logits = self.cls_head(x)\n\n        return F.squeeze(logits)\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"ctx = mx.gpu()\ncls_net = ResNetSteel(num_classes=4)\ncls_net.collect_params().initialize()\ncls_net.load_parameters('../input/mxnet-gluon-classification/unet_4_0.0.params')\ncls_net.collect_params().reset_ctx(ctx)"},{"cell_type":"code","execution_count":0,"metadata":{"_cell_guid":"3d0d817d-9d0c-4dfc-8de4-5bdb2ea95c6c","_uuid":"360d584a-54dc-4f71-aa50-56a5a5ef67c3","trusted":false},"outputs":[],"source":"\nunet = ResNetUnet(output_channels=[256, 128, 64, 32], num_classes=5)\nunet.load_parameters('../input/mxnet-gluon-baseline/unet_34_-1.params')\nunet.collect_params().reset_ctx(ctx)"},{"cell_type":"code","execution_count":0,"metadata":{"_cell_guid":"ca90bde7-c61f-48a8-95bd-2eb309a45059","_uuid":"b43b2a48-6895-45b8-8d77-6b9e08a0b723","trusted":false},"outputs":[],"source":"def mask2rle(mask):\n    if np.sum(mask) == 0: return ''\n    ar = mask.flatten(order='F')\n    EncodedPixel = ''\n    l = 0\n    for i in range(len(ar)):\n        if ar[i] == 0:\n            if l > 0:\n                if EncodedPixel != '': EncodedPixel += ' '\n                EncodedPixel += str(st+1)+' '+str(l)\n                l = 0\n        else: # == 1\n            if l == 0: st = i\n            l += 1\n    return EncodedPixel"},{"cell_type":"code","execution_count":null,"metadata":{"trusted":false},"outputs":[],"source":"import cv2\ndef remove_small_one(predict, min_size):\n    H,W = predict.shape\n    num_component, component = cv2.connectedComponents(predict.astype(np.uint8))\n    predict = np.zeros((H,W), np.bool)\n    for c in range(1,num_component):\n        p = (component==c)\n        if p.sum()>min_size:\n            predict[p] = True\n    return predict\n"},{"cell_type":"code","execution_count":null,"metadata":{"trusted":false},"outputs":[],"source":"def sharpen(p,t=0.5):\n        if t!=0:\n            return p**t\n        else:\n            return p"},{"cell_type":"code","execution_count":0,"metadata":{"_cell_guid":"5de58519-0966-4023-82c9-0dbce4b105f3","_uuid":"5589884a-9bc1-4a3a-b027-72aeab787666","trusted":false},"outputs":[],"source":"import random\nimport time\n# test_stage\ntrans = transforms.Compose(\n            [\n                transforms.ToTensor(),\n                transforms.Normalize(\n                    mean=(0.485, 0.456, 0.406),\n                   std=(0.229, 0.224, 0.225)\n                )\n            ]\n        )\n\ntest_dir = \"../input/severstal-steel-defect-detection/test_images/\"\n\nimglists = glob.glob(test_dir + '/*g')\noriims = []\npreds = []\ncls_preds = []\nrandom.shuffle(imglists)\nImageId_ClassIds = []\nEncodedPixels = []\n\naugs = ['flip_lr', 'flip_ud']\nfrom tqdm import tqdm\nthresholds = [0.5, 0.5, 0.5, 0.5]\nmin_area = [600, 600, 1000, 2000]\n# min_area = [1, 1, 1, 1]\nt1 = time.time()\nfor i, item in enumerate(tqdm(imglists)):\n    timg = cv2.imread(item)[:, :, ::-1]\n    img = mx.nd.array([timg])\n    input_img = trans(img)\n    num_aug = 0\n    \n    if 1:\n        cls_out = cls_net(input_img.as_in_context(ctx))\n        cls_out = F.sigmoid(cls_out, axis=1)\n        cls_out_mask = cls_out\n        cls_ind = F.where(cls_out > 0.5, F.ones_like(cls_out), F.zeros_like(cls_out))\n        out = unet(input_img.as_in_context(ctx))\n        out = F.softmax(out, axis=1)\n        # out = F.where(out > 0.5, out, F.zeros_like(out))\n        pred_inds = F.argmax(out, axis=1)\n        oriims.append(timg)\n        preds.append(pred_inds)\n        cls_preds.append(cls_ind)\n        out_mask = sharpen(out, 0)\n        \n        num_aug += 1\n    if 'flip_lr' in augs:\n        input_img_lr = F.flip(input_img, axis=3)\n        cls_out = cls_net(input_img_lr.as_in_context(ctx))\n        cls_out = F.sigmoid(cls_out, axis=1)\n        cls_out_mask += sharpen(cls_out)\n\n        out = unet(input_img_lr.as_in_context(ctx))\n        out = F.softmax(out, axis=1)\n        # out = F.where(out > 0.5, out, F.zeros_like(out))\n        out_mask += sharpen(F.flip(out, axis=3))\n        num_aug += 1\n\n    # if 'flip_ud' in augs:\n    #     input_img_lr = F.flip(input_img, axis=2)\n    #     out = unet(input_img_lr.as_in_context(ctx))\n    #     out = F.softmax(out, axis=1)\n    #     # out = F.where(out > 0.5, out, F.zeros_like(out))\n    #     out_mask += sharpen(F.flip(out, axis=2))\n    #     num_aug += 1\n\n    cls_out_mask = cls_out_mask * 1.0 / num_aug\n\n    out_mask = out_mask * 1.0 / num_aug\n    out = out_mask[:, 1:, :, :].asnumpy()\n    cls_out = cls_out_mask.asnumpy()\n    ImageId = item.split('/')[-1]\n    pred_inds = pred_inds.asnumpy()\n    for j in range(4):\n        Id = ImageId + '_'+str(j+1)\n        if cls_out.max() > 0.2:\n            tmp_mask = np.where(out[:, j, :, :] > thresholds[j], 1.0, 0)\n            tmp_mask = remove_small_one(tmp_mask[0], min_size=min_area[j]).astype(np.float)\n\n            # if np.sum(tmp_mask) < min_area[j]:\n            #     tmp_mask = np.zeros_like(tmp_mask)\n\n            # if np.sum(tmp_mask) < 10:\n            #     EncodedPixel = ''\n            # else:\n            EncodedPixel = mask2rle(tmp_mask)\n        else:\n            EncodedPixel = ''\n        ImageId_ClassIds.append(Id)\n        EncodedPixels.append(EncodedPixel)\ndur = time.time() - t1\nprint(\"cost time:{}\".format(dur))"},{"cell_type":"code","execution_count":0,"metadata":{"_cell_guid":"8d0ba6a1-411d-46c4-9265-c9a270076993","_uuid":"08dbbd25-6253-4fc3-9995-8343cc84f272","trusted":false},"outputs":[],"source":"submission =  pd.read_csv(\"../input/severstal-steel-defect-detection/sample_submission.csv\")\nprint(len(ImageId),len(submission['ImageId_ClassId']))\n# len(set(submission['ImageId_ClassId'])-set(Ids))\n# assert set(Ids) == set(submission['ImageId_ClassId'])\n\nfor i, encoded in zip(ImageId_ClassIds,EncodedPixels):\n    submission.loc[submission['ImageId_ClassId']==i,[\"EncodedPixels\"]] =  encoded\n\nsubmission.to_csv('submission.csv',index=False)"},{"cell_type":"code","execution_count":0,"metadata":{"_cell_guid":"33d4b2f4-8fd6-4316-bdac-c022851819c7","_uuid":"c6505d7a-4ce8-4333-bbe6-05a6cf97ed61","trusted":false},"outputs":[],"source":"submission.head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fdaacac1-4d6b-4dd3-9307-0064c7bc5423","_uuid":"d3928e77-1742-4af3-92f0-745367336cf0","trusted":false},"outputs":[],"source":"fig, ax1 = plt.subplots(figsize=(50, 50))\nfor i, (timg, pred_inds, cls_preds) in enumerate(zip(oriims[:100], preds[:100], cls_preds[:100)):\n#     plt.subplot(len(oriims[:100])*2, 1, i*2+1)\n#     plt.imshow(timg)\n#     plt.subplot(len(oriims[:100])*2, 1, i*2+2)\n#     plt.imshow(pred_inds[0].asnumpy())\n    seg_map = np.expand_dims(pred_inds[0].asnumpy(), axis=2)\n    seg_map_3c=np.repeat(seg_map, 3, 2)*255\n    h, w = timg.shape[:2]\n    seg_map_3c = cv2.resize(seg_map_3c, dsize=(w, h), interpolation=cv2.INTER_LINEAR)\n    att_im = cv2.addWeighted(seg_map_3c.astype(np.uint8), 0.5, timg, 0.5, 0.0)\n    if i > 10:\n        break\n    print(cls_preds)\n    plt.subplot(11, 1, i+1)\n    plt.imshow(att_im)"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}